# -*- coding: utf-8 -*-
"""ПР2 ТИМО Саврасов ПА

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rJJT6pEBwSgZjl_yjD31FTHcju2qjPUo
"""

!pip install kaggle

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# Решить задачу регрессии
* Сравнить результаты численного решения с аналитическим

$$ y(x) = x0*w0 + x1*w1 $$
"""

# результат работы модели -- это скалярное произведение весов w на значения признаков x
def linear_prediction(X, w):
    return np.dot(X, w)

def loss(X,y,w):
  L = (linear_prediction(x, w) - np.array(y)) ** 2 / len(y)
  return L

#необходимо реализовать численную оптимизацию функции стоиомости (градиентный спуск)
#на вход подается матрица признаков Х, целевая переменная y, веса и скорость обучения lr (параметр альфа)
#функция стоимости -- MSE
def optim(x,w,y,lr=0.001):
    grad = 2 * np.dot(linear_prediction(x, w) - y, x) / len(y)
    w = w - lr * grad
    return w

x = [6.1101, 5.5277, 8.5186, 7.0032, 5.8598, 8.3829, 7.4764, 8.5781, 6.4862, 5.0546, 5.7107, 14.164, 5.734, 8.4084, 5.6407, 5.3794,
    6.3654, 5.1301, 6.4296, 7.0708, 6.1891, 20.27, 5.4901, 6.3261, 5.5649, 18.945, 12.828, 10.957, 13.176, 22.203, 5.2524, 6.5894,
    9.2482, 5.8918, 8.2111, 7.9334, 8.0959, 5.6063, 12.836, 6.3534, 5.4069, 6.8825, 11.708, 5.7737, 7.8247, 7.0931, 5.0702, 5.8014,
    11.7, 5.5416, 7.5402, 5.3077, 7.4239, 7.6031, 6.3328, 6.3589, 6.2742, 5.6397, 9.3102, 9.4536, 8.8254, 5.1793, 21.279, 14.908, 18.959,
    7.2182, 8.2951, 10.236, 5.4994, 20.341, 10.136, 7.3345, 6.0062, 7.2259, 5.0269, 6.5479, 7.5386, 5.0365, 10.274, 5.1077, 5.7292, 5.1884,
    6.3557, 9.7687, 6.5159, 8.5172, 9.1802, 6.002, 5.5204, 5.0594, 5.7077, 7.6366, 5.8707, 5.3054, 8.2934, 13.394, 5.4369]
y = [17.592, 9.1302, 13.662, 11.854, 6.8233, 11.886, 4.3483, 12, 6.5987, 3.8166, 3.2522, 15.505, 3.1551, 7.2258, 0.71618, 3.5129, 5.3048, 0.56077,
     3.6518, 5.3893, 3.1386, 21.767, 4.263, 5.1875, 3.0825, 22.638, 13.501, 7.0467, 14.692, 24.147, -1.22, 5.9966, 12.134, 1.8495, 6.5426, 4.5623,
     4.1164, 3.3928, 10.117, 5.4974, 0.55657, 3.9115, 5.3854, 2.4406, 6.7318, 1.0463, 5.1337, 1.844, 8.0043, 1.0179, 6.7504, 1.8396, 4.2885, 4.9981,
     1.4233, -1.4211, 2.4756, 4.6042, 3.9624, 5.4141, 5.1694, -0.74279, 17.929, 12.054, 17.054, 4.8852, 5.7442, 7.7754, 1.0173, 20.992, 6.6799, 4.0259,
     1.2784, 3.3411, -2.6807, 0.29678, 3.8845, 5.7014, 6.7526, 2.0576, 0.47953, 0.20421, 0.67861, 7.5435, 5.3436, 4.2415, 6.7981, 0.92695, 0.152, 2.8214,
     1.8451, 4.2959, 7.2029, 1.9869, 0.14454, 9.0551, 0.61705]

w = [0, 0]
X = np.hstack((np.ones((len(x), 1)), np.array(x).reshape(-1, 1)))

plt.figure(figsize=(5,5))
plt.grid()
for _ in range(10000):
  w = optim(X,w,y)
  plt.plot(x, linear_prediction(X, w), c = 'r')
print(w)
plt.scatter(x,y)
plt.show()

#найдем аналитическое решение
X = np.hstack((np.ones((len(x), 1)), np.array(x).reshape(-1, 1)))
W = np.linalg.inv(np.dot(X.T, X)).dot(X.T).dot(y)
Y = np.dot(X, W)
print(W)
plt.figure(figsize=(5,5))
plt.plot(x, Y, c = 'r')
plt.grid()
plt.scatter(x,y)
plt.show()

"""# Решить задачу регрессии для прогнозирования ...
Использовать линейную регрессию без регуляризации, с регуляризацией Тихонова, и лассо регуляризацией, сравнить результаты

Данные можно скачать двумя способами:

* Скачать данные с Kaggle, в Google Colab нажать слева значок папки и перетащить данные туда
* С помощью Kaggle API
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

import warnings
warnings.filterwarnings('ignore')

from google.colab import files
files.upload()

#!mkdir ~/.kaggle #создание папки
!cp kaggle.json ~/.kaggle #копия этого файла в эту папку
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download 'spscientist/students-performance-in-exams'

!unzip students-performance-in-exams.zip

data = pd.read_csv("StudentsPerformance.csv")
print(data.shape)
data.head()

data.info()

data.columns

#data.drop('...', axis = 1, inplace = True)

data.isna().sum()

#выделим категориальные признаки и числовые
#метод select_dtypes возвращает подмножество столбцов фрейма данных на основе dtypes столбцов
categorical_cols = data.select_dtypes(include=["object"]).columns.tolist()
print(len(categorical_cols))
categorical_cols

numeric_cols = data.select_dtypes(exclude=["object"]).columns.tolist()
print(len(numeric_cols))
numeric_cols

#посмотрим, какое количество уникальных значений имеют категориальные признаки и числовые
unic_categ = pd.DataFrame([[i,data[i].nunique()] for i in categorical_cols], columns=['column_name','num_unique']).sort_values(by=['num_unique'])

unic_categ

unic_numer = pd.DataFrame([[i,data[i].nunique()] for i in numeric_cols], columns=['column_name','num_unique']).sort_values(by=['num_unique'])

unic_numer

data.gender.value_counts()

data['race/ethnicity'].value_counts()

data['parental level of education'].value_counts()

data.lunch.value_counts()

data['test preparation course'].value_counts()

print(f'Кол-во категориальных признаков = {len(categorical_cols)}')
print(f'Кол-во числовых признаков = {len(numeric_cols)}')

target_name = 'math score'
numeric_cols.remove('math score')

#визуализация

plt.hist(data[target_name], bins = 20, edgecolor='white')
plt.show()


fig = px.box(data_frame=data, y=target_name, width=700)
fig.show()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    data.drop(target_name, axis=1),
    data[target_name],
    test_size=0.3,
    random_state=1,
    shuffle=True
)

print(X_train.shape)
print(y_train.shape)
print()
print(X_test.shape)
print(y_test.shape)

#сделаем одну выборку с нормализованными численными признаками
from sklearn.preprocessing import StandardScaler

  X_train_num = X_train[numeric_cols]
  X_test_num = X_test[numeric_cols]

  scaler = StandardScaler()
  X_train_num_scaled = scaler.fit_transform(X_train_num)
  X_test_num_scaled = scaler.transform(X_test_num)

X_train[categorical_cols], X_train[categorical_cols].shape

# Кодирование категориальных признаков
from sklearn.preprocessing import OrdinalEncoder

encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)

X_train_cat = encoder.fit_transform(X_train[categorical_cols]).astype(int)
X_test_cat = encoder.fit_transform(X_test[categorical_cols]).astype(int)

X_train_new = np.hstack((X_train_num_scaled, X_train_cat))
X_test_new = np.hstack((X_test_num_scaled, X_test_cat))
X_train_new.shape, X_test_new.shape

np.random.seed(1)
model_lr = LinearRegression()

model_lr.fit(X_train_new, y_train)

pred_lr = model_lr.predict(X_test_new) # получение предсказаний на тестовой выборке
mse = mean_squared_error(y_test, pred_lr)
r2 = r2_score(y_test, pred_lr)
mae = mean_absolute_error(y_test, pred_lr)
print("Средняя ошибка прогноза балла по математике:", mae)
print("MSE = {}; R2 = {}".format(round(mse, 3), round(r2, 4)))

model_lr.intercept_

np.random.seed(1)
model_lasso = Lasso()

model_lasso.fit(X_train_new, y_train)

pred_lr_lasso = model_lasso.predict(X_test_new) # получение предсказаний на тестовой выборке
mse = mean_squared_error(y_test, pred_lr_lasso)
r2 = r2_score(y_test, pred_lr_lasso)
mae = mean_absolute_error(y_test, pred_lr_lasso)
print("Средняя ошибка прогноза балла по математике:", mae)
print("MSE = {}; R2 = {}".format(round(mse, 3), round(r2, 4)))

np.random.seed(1)
model_ridge = Ridge()

model_ridge.fit(X_train_new, y_train)

pred_lr_ridge = model_ridge.predict(X_test_new) # получение предсказаний на тестовой выборке
mse = mean_squared_error(y_test, pred_lr_ridge)
r2 = r2_score(y_test, pred_lr_ridge)
mae = mean_absolute_error(y_test, pred_lr_ridge)
print("Средняя ошибка прогноза балла по математике:", mae)
print("MSE = {}; R2 = {}".format(round(mse, 3), round(r2, 4)))

plt.plot(y_test,y_test)
plt.scatter(pred_lr,y_test, color = 'pink', label = 'LR',s=30,edgecolor='black', linewidths=0.5)
plt.xlabel('Предсказания')
plt.ylabel('Таргет')
plt.legend()
plt.plot()

plt.plot(y_test,y_test)
plt.scatter(pred_lr_lasso,y_test, color = 'crimson', label = 'Lasso',s=30,edgecolor='black', linewidths=0.5)
plt.xlabel('Предсказания')
plt.ylabel('Таргет')
plt.legend()
plt.plot()

plt.plot(y_test,y_test)
plt.scatter(pred_lr_ridge,y_test, color = 'c', label = 'Ridge',s=30,edgecolor='black', linewidths=0.5)
plt.xlabel('Предсказания')
plt.ylabel('Таргет')
plt.legend()
plt.plot()