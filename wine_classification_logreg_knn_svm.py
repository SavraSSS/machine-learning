# -*- coding: utf-8 -*-
"""ПР3 ТИМО Саврасов ПА

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17_okQpg-NpiA4FKr9mkTZgYN0pM1XX3j
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import sklearn

import warnings
warnings.filterwarnings('ignore')

!unzip archive.zip

data = pd.read_csv("wine.csv")
print(data.shape)
data.head()

data.describe()

#предобработать, проверить выбросы, пропуски, есть ли дисбаланс классов и прочее
data.isna().sum()

trg = data.get('Cultivar')
trg.head()

unique_values = trg.value_counts()
unique_values

#data = data.drop('Id', axis=1)
#data.head()

uniq_trg = list(set(trg))
trg_dict = dict(zip(uniq_trg, range(len(uniq_trg))))
trg = trg.replace(to_replace=uniq_trg, value=list(trg_dict.values()))
uniq_trg

#data_dummies = pd.get_dummies(data, prefix=["SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm"])
#data_dummies = data_dummies[data_dummies.columns].astype('float')

#new
data_dummies = data.drop('Cultivar', axis = 1)

plt.hist(trg)
plt.show()

from sklearn.model_selection import train_test_split
#разделить на обучающую и тестовую выборки
X_train, X_test, Y_train, Y_test = train_test_split(data_dummies,
                                                    trg,
                                                    test_size = 0.2,
                                                    random_state=123)

print(X_train.shape)
print(X_test.shape)

from imblearn.under_sampling import RandomUnderSampler
# Создание объекта RandomUnderSampler
rus = RandomUnderSampler(random_state=0)
# Применение under-sampling к x_train и y_train
X_train, Y_train = rus.fit_resample(X_train, Y_train)

X_train, Y_train

"""# Логистическая регрессия"""

from sklearn.linear_model import LogisticRegression
#обучить логистическую регрессию
model_logReg = LogisticRegression()
model_logReg.fit(X_train, Y_train)
preds = model_logReg.predict(X_test)

#вывести метрики accuracy, f1-score, PR и ROC кривые, PR и ROC AUC, матрицу ошибок
#может пригодиться from sklearn.metrics import classification_report

from sklearn.metrics import precision_recall_curve
from sklearn.metrics import auc
# для построения кривых можно воспользоваться from sklearn.preprocessing import label_binarize
# для построения кривых необходимо использовать метки тергета 0 и 1 в качестве первого аргумента
# и вероятности попадания в класс, можно получить, используя predict_proba
from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score, confusion_matrix, auc
from sklearn.preprocessing import label_binarize

def metrics(test, pred):

  print(classification_report(test, pred))

  cm = confusion_matrix(test, pred)
  print("Confusion matrix:")
  print(cm)

  test = label_binarize(test, classes=[0, 1, 2])
  pred = label_binarize(pred, classes=[0, 1, 2])

  for i in range(3):
    precision, recall, _ = precision_recall_curve(test[:, i], pred[:, i])
    pr_auc = auc(recall, precision)
    plt.plot(recall, precision, lw=2, label=f'Class {i} (AUC = {pr_auc:.2f})')

  plt.xlabel('Recall')
  plt.ylabel('Precision')
  plt.legend(loc='lower left')
  plt.title('Precision-Recall Curve')
  plt.show()

  for i in range(3):
    fpr, tpr, _ = roc_curve(test[:, i], pred[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')

  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.legend(loc='lower right')
  plt.title('Receiver Operating Characteristic (ROC) Curve')
  plt.show()

metrics(Y_test, preds)

"""classification_report

Support: количество наблюдений для каждого класса

Подходы к усреднению метрик

micro = accuracy (сумма верных срабатываний для всех классов, деленная на все объекты)

Macro avg: среднее арифметическое показателя между классами

weighted avg: средневзвешенное значение рассчитывается путем произведения оценки показателя каждого класса на его количество наблюдений, последующее суммирование результата и деление результата на сумму наблюдений

Зачем?

* Удобно, когда классов очень много
* micro - когда классы сбалансированы
* macro - каждому классу даем одинаковый вес, вне зависимости от дисбаланса классов, хорошо использовать, если нам важен меньший класс, например, мошеннические транзакции, которых мало, а хороших транзакций много, при плохой модели мы получим низкую macro метрику
* weighted - учитываем размер каждого класса, даем класса вес, согласно их количеству. Если меньший класс нам не важен, то мы можем им принебречь при подсчете метрики. Если macro сильно среагирует на ошибки на малом классе, то weighted нет.

# KNN
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# использовать алгоритм KNN из sklearn

number_of_neighbors = np.arange(25) #количество соседей для перебора
model_KNN = KNeighborsClassifier()
params = {"n_neighbors": number_of_neighbors}

grid_search = GridSearchCV(estimator = model_KNN,
                           param_grid = params)#использовать GridSearchCV для поиска оптимального гиперпараметра

grid_search.fit(X_train, Y_train) #обучение модели

grid_search.best_estimator_ # лучшая модель получается при k =

preds_knn = grid_search.predict(X_test) # результат работы модели на тесте

#вывести метрики accuracy, f1-score, PR и ROC кривые, PR и ROC AUC, матрицу ошибок
metrics(Y_test, preds_knn)

"""# SVM"""

from sklearn.svm import SVC

#использовать SVM для решения задачи классификации
param_kernel = ('linear', 'rbf', "poly", "sigmoid") # ядра
params = {'kernel':param_kernel}

model_SVC = SVC()
grid_search_svm = GridSearchCV(estimator=model_SVC, param_grid=params)
grid_search_svm.fit(X_train, Y_train)
grid_search_svm.best_estimator_
#аналогично как и для KNN, найти оптимальное ядро
#вывести метрики

preds_svm = grid_search_svm.predict(X_test)
metrics(Y_test, preds_svm)